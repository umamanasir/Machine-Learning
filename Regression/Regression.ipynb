{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "03373c37",
      "metadata": {
        "id": "03373c37"
      },
      "source": [
        "# Machine Learning (CS535): Assignment 2\n",
        "## Linear and Logistic Regression\n",
        "#### Name: Umama Nasir Abbasi\n",
        "#### Roll Number: 23100265"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b52f8f19",
      "metadata": {
        "id": "b52f8f19"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "\n",
        "*   The aim of this assignment is to implement linear and logistic regression from scratch.\n",
        "*   You must use the Python programming language.\n",
        "*   You can add as many code/markdown cells as required.\n",
        "*   ALL cells must be run (and outputs visible) in order to get credit for your work.\n",
        "*   Please use procedural programming style and comment your code thoroughly.\n",
        "*   There are two parts of this assignment. In part 1, you can use **NumPy**, **Pandas**, **Matplotlib**, **Seaborn**, and any other standard Python libraries. You are $\\color{red}{\\text{not allowed}}$ to use **scikit-learn**, or any other machine learning toolkit. You can only use **scikit-learn** in part 2.\n",
        "*   **Carefully read the submission instructions and plagiarism policy.**\n",
        "*   Deadline to submit this assignment is 7th November 2022, 11:55pm on LMS.\n",
        "\n",
        "### Submission Instructions\n",
        "\n",
        "You should submit both your notebook file (.ipynb) and python script (.py) on LMS.\n",
        "Please name your files Name_RollNo_Assignment2. Zip these files in a folder and name\n",
        "the folder Name_RollNo_Assignment2. If you don't know how to save .ipynb as .py see\n",
        "[this](https://i.stack.imgur.com/L1rQH.png). Failing to submit any one of them might result in the reduction of marks.\n",
        "\n",
        "### Plagiarism Policy\n",
        "\n",
        "The code $\\color{red}{\\text{MUST}}$ be done independently. Any plagiarism or cheating of work from others\n",
        "or the internet will be immediately referred to the DC. If you are confused about what\n",
        "constitutes plagiarism, it is your responsibility to consult with the instructor or the TA\n",
        "in a timely manner. **PLEASE DO NOT LOOK AT ANYONE ELSE'S CODE\n",
        "NOR DISCUSS IT WITH THEM.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d78cbb7c",
      "metadata": {
        "id": "d78cbb7c"
      },
      "source": [
        "### Introduction\n",
        "In this assignment, you will be implementing linerar regression and logistic regression models for the provided datasets from scratch. A description of the problem statement is given at the start of each part. \n",
        "\n",
        "Try to write modeular code as some of the functions you write for task 1 may be usable in task 2.\n",
        "\n",
        "Have fun!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb0858b",
      "metadata": {
        "id": "dfb0858b"
      },
      "source": [
        "## Task 1: Multivariate Linear Regression\n",
        "\n",
        "In this part, you will implement multivariate linear regression (from scratch) to predict the the median price of homes in a Boston suburb during the mid-1970s. To do this, you are given with the dataset that has 404 examples in the train set and 102 examples in test set. Each example has 13 input variables (features) and one output variable (price in $10,000s). Below is the description of input variables:\n",
        "\n",
        "- Per capita crime rate.\n",
        "- The proportion of residential land zoned for lots over 25,000 square feet.\n",
        "- The proportion of non-retail business acres per town.\n",
        "- Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
        "- Nitric oxides concentration (parts per 10 million).\n",
        "- The average number of rooms per dwelling.\n",
        "- The proportion of owner-occupied units built before 1940.\n",
        "- Weighted distances to five Boston employment centers.\n",
        "- Index of accessibility to radial highways.\n",
        "- Full-value property-tax rate per $10,000.\n",
        "- Pupil-teacher ratio by town.\n",
        "- 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
        "- Percentage lower status of the population.\n",
        "\n",
        "Each one of these input features is stored using a different scale. Some features are represented by a proportion between 0 and 1, other features are ranges between 1 and 12, some are ranges between 0 and 100, and so on. This is often the case with real-world data, and understanding how to explore and clean such data is an important skill to develop.\n",
        "\n",
        "A common way to normalize features that use different scales and ranges is:\n",
        "\n",
        "- Subtract the mean value of each feature from the dataset.\n",
        "- After subtracting the mean, additionally scale (divide) the feature values by their respective standard deviations.\n",
        "\n",
        "Note: We only use examples of the train set to estimate the mean and standard deviation.\n",
        "\n",
        "You have to follow exactly the same steps as above i.e. implement hypothesis, cost function and gradient descent for multivariate linear regression to learn parameters $\\theta$ using train set. Finally, report the cost (error) using your learned parameters $\\theta$ on test set. Expected Mean Square Error on this dataset is 11.5 - 12.5 approximately. \n",
        "\n",
        "We provide you with the code needed to load this dataset. The dataset is loaded from the data files into the variables `train_X`, `train_Y`, `test_X` and `test_Y`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7012f9a",
      "metadata": {
        "id": "a7012f9a"
      },
      "source": [
        "### Part A: Implementation from scratch\n",
        "\n",
        "Use the slides and textbook as a reference to write the gradient descent algorithm from scratch for this problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6691b1c9",
      "metadata": {
        "id": "6691b1c9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import glob \n",
        "import numpy as np \n",
        "import math \n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd302b60",
      "metadata": {
        "id": "bd302b60"
      },
      "outputs": [],
      "source": [
        "#reading data. \n",
        "\n",
        "train_X1 = pd.read_csv('Dataset/Task1/trainData.txt', sep = ' ', header = None)\n",
        "train_Y1 =  pd.read_csv('Dataset/Task1/trainLabels.txt', sep = ' ', header = None)\n",
        "test_X1  =  pd.read_csv('Dataset/Task1/testData.txt', sep = ' ', header = None)\n",
        "test_Y1  =  pd.read_csv('Dataset/Task1/testLabels.txt', sep = ' ', header = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ea8cb2f",
      "metadata": {
        "id": "6ea8cb2f"
      },
      "outputs": [],
      "source": [
        "# print(len(train_X))\n",
        "\n",
        "train_X = np.array(train_X1)\n",
        "train_Y = np.array(train_Y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ceede58",
      "metadata": {
        "id": "3ceede58"
      },
      "outputs": [],
      "source": [
        "def square_loss(prediction, actual): \n",
        "    m = prediction.shape[0]\n",
        "    square_loss = ( prediction - actual) ** 2\n",
        "    return np.array(np.sum(square_loss)/(2*m))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b74c6282",
      "metadata": {
        "id": "b74c6282"
      },
      "outputs": [],
      "source": [
        "def testMeasures(): \n",
        "    mean = []\n",
        "    std = []\n",
        "    for  i in range( train_X.shape[1]):\n",
        "        mean.append(np.mean(train_X[:,i]))\n",
        "        std.append(np.std(train_X[:,i]))\n",
        "    return np.array([mean,std])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2cabe5a",
      "metadata": {
        "id": "e2cabe5a"
      },
      "outputs": [],
      "source": [
        "def normalize(x): \n",
        "    #mean/std for each class. \n",
        "    \n",
        "    j = testMeasures()\n",
        "    print(j.shape)\n",
        "    mean = j[0].flatten()\n",
        "    std = j[1]\n",
        "    print(len(mean))\n",
        "    print(x.shape)\n",
        "    y = np.zeros(x.shape)\n",
        "    for i in range(x.shape[1]):\n",
        "        m = mean[i]\n",
        "        s = std[i]\n",
        "        y[:,i] = ( (x[:,i] - m) / s )\n",
        "    return y  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3b602b",
      "metadata": {
        "id": "5a3b602b"
      },
      "outputs": [],
      "source": [
        "def prediction_linear(x, theta): \n",
        "    return np.dot(x,theta)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb90f290",
      "metadata": {
        "id": "cb90f290"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gradient_descent (predicted, alpha, theta, train_Label, train_X):\n",
        "    m = train_X.shape[0]\n",
        "    differential = (1/m)* np.dot(train_X.transpose(), ( predicted - train_Label) )\n",
        "    tempJ = theta - (alpha * differential)\n",
        "    tempJ = np.array(tempJ)\n",
        "    return tempJ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f23bf214",
      "metadata": {
        "id": "f23bf214"
      },
      "outputs": [],
      "source": [
        "def Linear_Regression(train_X, train_label, epochs, alpha, theta):\n",
        "    train_X = normalize(train_X)\n",
        "    x_0 =np.ones((train_X.shape[0],1))\n",
        "    train_X = np.append(train_X, x_0, axis=1)\n",
        "    for i in range(epochs): \n",
        "        predict = prediction_linear(train_X, theta)\n",
        "        cost = square_loss(predict, train_label)\n",
        "        print(\"epoch: \", i, \" cost is: \", cost)\n",
        "        theta = gradient_descent(predict,alpha, theta, train_label, train_X )\n",
        "    return theta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b838bdaf",
      "metadata": {
        "id": "b838bdaf",
        "outputId": "313a921c-b294-4b2f-ef0d-6b8218cd6665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 13)\n",
            "13\n",
            "(404, 13)\n",
            "epoch:  0  cost is:  [289.508191]\n",
            "epoch:  1  cost is:  [220.41372074]\n",
            "epoch:  2  cost is:  [178.40908848]\n",
            "epoch:  3  cost is:  [146.4721651]\n",
            "epoch:  4  cost is:  [120.93557173]\n",
            "epoch:  5  cost is:  [100.31641344]\n",
            "epoch:  6  cost is:  [83.63425287]\n",
            "epoch:  7  cost is:  [70.12918749]\n",
            "epoch:  8  cost is:  [59.19212422]\n",
            "epoch:  9  cost is:  [50.33168712]\n",
            "epoch:  10  cost is:  [43.15093205]\n",
            "epoch:  11  cost is:  [37.32906914]\n",
            "epoch:  12  cost is:  [32.60679387]\n",
            "epoch:  13  cost is:  [28.77446325]\n",
            "epoch:  14  cost is:  [25.66255522]\n",
            "epoch:  15  cost is:  [23.13396755]\n",
            "epoch:  16  cost is:  [21.07779985]\n",
            "epoch:  17  cost is:  [19.4043318]\n",
            "epoch:  18  cost is:  [18.04096676]\n",
            "epoch:  19  cost is:  [16.92895436]\n",
            "epoch:  20  cost is:  [16.0207421]\n",
            "epoch:  21  cost is:  [15.27783482]\n",
            "epoch:  22  cost is:  [14.66906432]\n",
            "epoch:  23  cost is:  [14.1691904]\n",
            "epoch:  24  cost is:  [13.75776963]\n",
            "epoch:  25  cost is:  [13.41824048]\n",
            "epoch:  26  cost is:  [13.13718331]\n",
            "epoch:  27  cost is:  [12.90372187]\n",
            "epoch:  28  cost is:  [12.70903892]\n",
            "epoch:  29  cost is:  [12.54598445]\n",
            "epoch:  30  cost is:  [12.40875855]\n",
            "epoch:  31  cost is:  [12.29265483]\n",
            "epoch:  32  cost is:  [12.19385263]\n",
            "epoch:  33  cost is:  [12.10924898]\n",
            "epoch:  34  cost is:  [12.03632239]\n",
            "epoch:  35  cost is:  [11.97302268]\n",
            "epoch:  36  cost is:  [11.91768175]\n",
            "epoch:  37  cost is:  [11.86894126]\n",
            "epoch:  38  cost is:  [11.82569413]\n",
            "epoch:  39  cost is:  [11.78703712]\n"
          ]
        }
      ],
      "source": [
        "theta = np.random.random(size = (train_X.shape[1]+1, 1))\n",
        "updated = Linear_Regression(train_X, train_Y, 40, 0.1, theta)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "163e42a3",
      "metadata": {
        "id": "163e42a3",
        "outputId": "cf2580f2-cf93-4597-d270-2878adae2b6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 13)\n",
            "13\n",
            "(102, 13)\n"
          ]
        }
      ],
      "source": [
        "x0_test = np.ones((test_X1.shape[0],1))\n",
        "test_X = np.array(test_X1) \n",
        "test_X = normalize(test_X)\n",
        "test_Y = np.array(test_Y1)\n",
        "test_X = np.append(test_X, x0_test, axis  =1)\n",
        "# print(x0_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66772920",
      "metadata": {
        "id": "66772920",
        "outputId": "b9f9fe13-8074-4061-c7a0-9121063d4ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cost:  10.823946750475615\n"
          ]
        }
      ],
      "source": [
        "linear_prediction = prediction_linear(test_X, updated)\n",
        "linear_cost = square_loss(linear_prediction, test_Y)\n",
        "print(\"cost: \", linear_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d133d738",
      "metadata": {
        "id": "d133d738"
      },
      "source": [
        "### Part B: Regularized Linear Regression Using Scikit-learn\n",
        "\n",
        "Now, you'll use the [scikit-learn](https://scikit-learn.org/stable/index.html) to implement [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge), [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso), [Elastic Net](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet) and apply them to Boston house pricing dataset (provided in part 2). Try out different values of regularization coefficient (known as alpha in scikit-learn) and use the [Mean Squared Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) to report loss with each regression. Finally, plot the regularization coefficients alpha (x-axis) with learned parameters $\\theta$ (y-axis) for Ridge and Lasso. Please read [this blog](https://scienceloft.com/technical/understanding-lasso-and-ridge-regression/) to get better understanding of the desired plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c155552f",
      "metadata": {
        "id": "c155552f"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from matplotlib import pyplot as plt \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf7026c6",
      "metadata": {
        "id": "bf7026c6"
      },
      "outputs": [],
      "source": [
        "test_X = np.array(test_X1) \n",
        "test_Y = np.array(test_Y1)\n",
        "# print(x0_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d68e4dd9",
      "metadata": {
        "id": "d68e4dd9",
        "outputId": "33f17836-466b-48b7-f0fe-3475092ffd53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score:  23.195599256422998\n"
          ]
        }
      ],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(train_X1, train_Y1)\n",
        "pred =model.predict(test_X)\n",
        "score = mean_squared_error(test_Y, pred)\n",
        "print(\"Score: \", score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f68454",
      "metadata": {
        "id": "f3f68454",
        "outputId": "e7443b32-f8fe-4940-e70a-cf220a31ff6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score:  25.286946353411157\n"
          ]
        }
      ],
      "source": [
        "en_model = ElasticNet()\n",
        "en_model.fit(train_X1, train_Y1)\n",
        "pred = en_model.predict(test_X)\n",
        "score = mean_squared_error(test_Y, pred)\n",
        "print(\"Score: \", score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2242e19",
      "metadata": {
        "id": "e2242e19",
        "outputId": "52353ac0-728e-4210-e495-c16c89ad88d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE -  22.573889366935223  Alpha:  [2.00e-04 5.00e-04 1.00e-04 1.00e-02 9.00e-01 2.34e-01 5.00e-04 1.00e-04\n",
            " 6.00e-01]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ridge regularization vs parameters')"
            ]
          },
          "execution_count": 328,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "alpha = np.array([0.0002, 0.0005, 0.0001, 0.01, 0.9, 0.234, 0.0005, 0.0001, 0.6])\n",
        "coeffecient = []\n",
        "mini = alpha[0]\n",
        "score_r = 100000000\n",
        "for a in alpha: \n",
        "    rid = Ridge(a)\n",
        "    rid.fit(train_X1, train_Y1)\n",
        "    prediction_rid = rid.predict(test_X)\n",
        "    c = mean_squared_error(test_Y, prediction_rid)\n",
        "    if c < score_r: \n",
        "        score_r = c\n",
        "        mini = alpha\n",
        "    coeffecient.append(rid.coef_.flatten())\n",
        "\n",
        "\n",
        "\n",
        "print(\"MSE - \", score_r, \" Alpha: \", mini)\n",
        "coeffecient = np.array(coeffecient)\n",
        "plt.plot(alpha, coeffecient)\n",
        "plt.xlabel(\"Value of alpha\")\n",
        "plt.ylabel(\"Values of thetas \")\n",
        "plt.title(\"Ridge regularization vs parameters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797d9506",
      "metadata": {
        "id": "797d9506"
      },
      "source": [
        "## Task 2: Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5216e2a",
      "metadata": {
        "id": "b5216e2a"
      },
      "source": [
        "#### Problem:\n",
        "The purpose of this assignment is to get you familiar with sentiment classification. By the end of this assignment you will have your very own “Sentiment Analyzer”. You are given with Large Movie Review Dataset that contains separate labelled train and test set. Your task is to train a Logistic Regression classifier on train set and report accuracy on test set.\n",
        "\n",
        "#### Dataset:\n",
        "The core dataset contains 50,000 reviews split evenly into 25k train and 25k test sets. The overall distribution of labels is balanced (25k pos and 25k neg). There are two top-level directories [train/, test/] corresponding to the training and test sets. Each contains [pos/, neg/] directories for the reviews with binary labels positive and negative. Within these directories, reviews are stored in text files named following the convention [[id]_[rating].txt] where [id] is a unique id and [rating] is the star rating for that review on a 1-10 scale. For example, the file [test/pos/200_8.txt] is the text for a positive-labeled test set example with unique id 200 and star rating 8/10 from IMDb.\n",
        "\n",
        "#### Preprocessing:\n",
        "In the preprocessing step you’re required to remove the stop words and punctuation marks and other unwanted characters from the reviews and convert them to lower case. You may find the string and regex module useful for this purpose. A stop word list is provided with the assignment statement.\n",
        "\n",
        "#### Feature Extraction:\n",
        "In the feature extraction step you can you’ll represent each review by the 3 features 𝑥0, 𝑥1, 𝑥2 and 1 class label 𝑦 as shown in the table below:\n",
        "\n",
        "| Feature | Definition | Comment |\n",
        "| --- | --- | --- |\n",
        "| x_0 | count(positive words) ∈ review | Positive lexicon is provided |\n",
        "| --- | --- | --- |\n",
        "| x_2 | count(negative words) ∈ review | Negative lexicon is provided |\n",
        "| --- | --- | --- |\n",
        "| y | 1 if positive, 0 otherwise | Mentioned in directory name |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94042de4",
      "metadata": {
        "id": "94042de4"
      },
      "outputs": [],
      "source": [
        "#Pre-Processing. \n",
        "file=open('Dataset/Task2/stop_words.txt','r')\n",
        "stopWords = file.read()\n",
        "punct =  r'[^\\w\\s]'\n",
        "breaks = r'<br/>'\n",
        "\n",
        "negatives = glob.glob('Dataset/Task2/train/neg'+ '/*.txt')\n",
        "final = []\n",
        "positives = glob.glob('Dataset/Task2/train/pos'+ '/*.txt')\n",
        "finalPos = [] \n",
        "\n",
        "for neg in negatives:\n",
        "    f=open(neg,'r', encoding=\"utf-8\")\n",
        "    sample = f.read()\n",
        "    sample = sample.lower()\n",
        "    res = re.sub(breaks, '', sample) \n",
        "    res2 = re.sub(punct, '', res) \n",
        "    res2 = res2.replace(stopWords, '') \n",
        "    final.append(res2)\n",
        "    f.close()\n",
        "    \n",
        "for pos in positives:\n",
        "    f=open(pos,'r', encoding=\"utf-8\")\n",
        "    sample = f.read()\n",
        "    sample = sample.lower()\n",
        "    res = re.sub(breaks, '', sample) \n",
        "    res2 = re.sub(punct, '', res) \n",
        "    res2 = res2.replace(stopWords, '') \n",
        "    finalPos.append(res2)\n",
        "    f.close()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f202ece",
      "metadata": {
        "id": "4f202ece"
      },
      "outputs": [],
      "source": [
        "#feature extraction. \n",
        "# x_0 = 1\n",
        "x_1 = [] # count of + words \n",
        "x_2 = [] # count of - words\n",
        "y = [] # final label. \n",
        "\n",
        "file=open('Dataset/Task2/positive_words.txt','r')\n",
        "positive_words = file.read()\n",
        "positive_words = positive_words.split()\n",
        "\n",
        "file=open('Dataset/Task2/negative_words.txt','r')\n",
        "negative_words = file.read()\n",
        "negative_words = negative_words.split()\n",
        "\n",
        "for review in final: #for each -ve review\n",
        "    positive = 0\n",
        "    negative = 0\n",
        "    review = review.split()\n",
        "    for word in review: #words in each reviews.\n",
        "        if word in positive_words: #if word exists in positive words\n",
        "            positive = positive + 1\n",
        "        if word in negative_words: #if word exists in negative words.\n",
        "            negative = negative + 1\n",
        "     \n",
        "    x_1.append(positive)\n",
        "    x_2.append(negative)\n",
        "    y.append(0)\n",
        "    \n",
        "    \n",
        "for review in finalPos: #for each +ve review\n",
        "    positive = 0\n",
        "    negative = 0\n",
        "    review = review.split()\n",
        "    for word in review: #words in each reviews.\n",
        "        if word in positive_words: #if word exists in positive words\n",
        "            positive = positive + 1\n",
        "        if word in negative_words: #if word exists in negative words.\n",
        "            negative = negative + 1 \n",
        "    x_1.append(positive)\n",
        "    x_2.append(negative)\n",
        "    y.append(1)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc79a7a",
      "metadata": {
        "id": "ffc79a7a"
      },
      "outputs": [],
      "source": [
        "#test. \n",
        "\n",
        "negativesTest = glob.glob('Dataset/Task2/test/neg'+ '/*.txt')\n",
        "negTestLabel = np.zeros(len(negativesTest))\n",
        "positivesTest = glob.glob('Dataset/Task2/test/pos'+ '/*.txt')\n",
        "posTestLabel = np.ones(len(positivesTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99e58cd",
      "metadata": {
        "id": "a99e58cd"
      },
      "outputs": [],
      "source": [
        "testN = []\n",
        "testP = []\n",
        "for neg in negativesTest:\n",
        "    f=open(neg,'r', encoding=\"utf-8\")\n",
        "    sample = f.read()\n",
        "    sample = sample.lower()\n",
        "    res = re.sub(breaks, '', sample) \n",
        "    res2 = re.sub(punct, '', res) \n",
        "    res2 = res2.replace(stopWords, '') \n",
        "    testN.append(res2)\n",
        "    f.close()\n",
        "    \n",
        "for pos in positivesTest:\n",
        "    f=open(pos,'r', encoding=\"utf-8\")\n",
        "    sample = f.read()\n",
        "    sample = sample.lower()\n",
        "    res = re.sub(breaks, '', sample) \n",
        "    res2 = re.sub(punct, '', res) \n",
        "    res2 = res2.replace(stopWords, '') \n",
        "    testP.append(res2)\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cafa447",
      "metadata": {
        "id": "4cafa447"
      },
      "outputs": [],
      "source": [
        "t_1 = []\n",
        "t_2 = []\n",
        "t_y = []\n",
        "for review in testN: #for each -ve review\n",
        "    positive = 0\n",
        "    negative = 0\n",
        "    review = review.split()\n",
        "    for word in review: #words in each reviews.\n",
        "        if word in positive_words: #if word exists in positive words\n",
        "            positive = positive + 1\n",
        "        if word in negative_words: #if word exists in negative words.\n",
        "            negative = negative + 1\n",
        "     \n",
        "    t_1.append(positive)\n",
        "    t_2.append(negative)\n",
        "    t_y.append(0)\n",
        "    \n",
        "    \n",
        "for review in testP: #for each +ve review\n",
        "    positive = 0\n",
        "    negative = 0\n",
        "    review = review.split()\n",
        "    for word in review: #words in each reviews.\n",
        "        if word in positive_words: #if word exists in positive words\n",
        "            positive = positive + 1\n",
        "        if word in negative_words: #if word exists in negative words.\n",
        "            negative = negative + 1 \n",
        "    t_1.append(positive)\n",
        "    t_2.append(negative)\n",
        "    t_y.append(1)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e175592b",
      "metadata": {
        "id": "e175592b"
      },
      "outputs": [],
      "source": [
        "#Train: \n",
        "\n",
        "x_1 = np.array(x_1)\n",
        "x_2 = np.array(x_2)\n",
        "x_2 = np.reshape(x_2, (x_2.shape[0],1))\n",
        "X = x_1\n",
        "X = np.reshape(X,(x_1.shape[0],1))\n",
        "X = np.append(X, x_2, axis=1)\n",
        "X = X.transpose()\n",
        "temp_X = X\n",
        "y = np.array(y)\n",
        "temp_y = y\n",
        "y = np.reshape(y, (y.shape[0],1))\n",
        "\n",
        "#Test:\n",
        "t_1 = np.array(t_1)\n",
        "t_2 = np.array(t_2)\n",
        "t_2 = np.reshape(t_2, (t_2.shape[0],1))\n",
        "X_test = t_1\n",
        "X_test = np.reshape(X_test,(t_1.shape[0],1))\n",
        "X_test = np.append(X_test, t_2, axis=1)\n",
        "X_test = X_test.transpose()\n",
        "yTest = np.array(t_y)\n",
        "yTest = np.reshape(yTest, (yTest.shape[0],1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ddb45c",
      "metadata": {
        "id": "d3ddb45c",
        "outputId": "982ce33e-0b1b-4f01-d9c3-620224321fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 25000)\n",
            "(2, 25000)\n",
            "(25000, 1)\n",
            "(25000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_test.shape)\n",
        "print(X.shape)\n",
        "print(yTest.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331017de",
      "metadata": {
        "id": "331017de"
      },
      "source": [
        "### Part A: Implementation from scratch\n",
        "\n",
        "#### Guidelines:\n",
        "Implement the following in order to complete this part:\n",
        "* Sigmoid function\n",
        "* Cross-entropy loss function\n",
        "* Batch Gradient Descent\n",
        "* Prediction function that predict whether the label is 0 or 1 for test reviews using learned logistic regression (use the decision threshold of 0.5)\n",
        "* Evaluation function that calculates classification accuracy and confusion matrix on test set (the expected accuracy on the test set is around 72%)\n",
        "* Report plots with no. of iterations/ epochs on x-axis and training/ validation loss on y-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78cb0908",
      "metadata": {
        "id": "78cb0908"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x): \n",
        "    s = 1 / (1 + np.exp(-x))\n",
        "    return s "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d5de57e",
      "metadata": {
        "id": "8d5de57e"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(predicted, actual): \n",
        "    predicted = predicted.transpose().flatten()\n",
        "    loss = - np.average( (actual* np.log(predicted+0.000000001)) + ((1-actual)* np.log((1-predicted)+0.000000001)))\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704a0457",
      "metadata": {
        "id": "704a0457"
      },
      "outputs": [],
      "source": [
        "\n",
        "def batch_gradient_descent(alpha, X, y ,theta, predicted): \n",
        "    differential = np.dot(X, (predicted - y))\n",
        "    differential = np.reshape(differential, (differential.shape[0],1))\n",
        "    tempJ = theta - (alpha * differential)\n",
        "    tempJ = np.array(tempJ)\n",
        "\n",
        "    return tempJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "245afd60",
      "metadata": {
        "id": "245afd60"
      },
      "outputs": [],
      "source": [
        "def prediction(x,t):\n",
        "    x = x.transpose()\n",
        "    l = np.dot(x,t)\n",
        "    return sigmoid(l)\n",
        " \n",
        " \n",
        "def predict(x, t, decision_threshold):\n",
        "    pred =  prediction(t,x).transpose().flatten()\n",
        "    ans = np.array([1 if p >= decision_threshold else 0 for p in pred])\n",
        "    return ans\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfdfaf32",
      "metadata": {
        "id": "dfdfaf32"
      },
      "outputs": [],
      "source": [
        "def normalizeLogistic(x): \n",
        "    mean = []\n",
        "    std = []\n",
        "    for  i in range( x.shape[1]):\n",
        "        mean.append(np.mean(x[:,i]))\n",
        "        std.append(np.std(x[:,i]))\n",
        "    \n",
        "    y = np.zeros(x.shape)\n",
        "    for i in range(x.shape[1]):\n",
        "        m = mean[i]\n",
        "        s = std[i]\n",
        "        y[:,i] = ((x[:,i] - m) / s)\n",
        "    return y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cc8c2c1",
      "metadata": {
        "id": "0cc8c2c1"
      },
      "outputs": [],
      "source": [
        "def Logistic_Regression(trainData, trainLabel, epochs, learning_rate , theta, decision_threshold):\n",
        "    trainData = normalizeLogistic(trainData)\n",
        "    x_0 = np.ones((trainData.shape[1], 1))  \n",
        "    c =[]\n",
        "    trainData = np.append(trainData, x_0.transpose(), axis =0)\n",
        "    for i in range (epochs): \n",
        "        h = predict(trainData, theta, decision_threshold)\n",
        "        cost = cross_entropy(h, trainLabel)\n",
        "        print(\"cost for i: \", i , \" = \", cost)\n",
        "        c.append(cost)\n",
        "        theta = batch_gradient_descent(learning_rate, trainData, trainLabel, theta, h)\n",
        "    a = np.array([theta, np.array(c)])    \n",
        "    return a\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be9e3432",
      "metadata": {
        "id": "be9e3432",
        "outputId": "bb524826-e964-4571-f2c9-86206642aee1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10712\\2530889262.py:12: RuntimeWarning: invalid value encountered in divide\n",
            "  y[:,i] = ((x[:,i] - m) / s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cost for i:  0  =  5.60688680411478\n",
            "cost for i:  1  =  10.361632917973209\n",
            "cost for i:  2  =  10.361632917973209\n",
            "cost for i:  3  =  10.361632917973209\n",
            "cost for i:  4  =  10.361632917973209\n",
            "cost for i:  5  =  10.361632917973209\n",
            "cost for i:  6  =  10.361632917973209\n",
            "cost for i:  7  =  10.361632917973209\n",
            "cost for i:  8  =  10.361632917973209\n",
            "cost for i:  9  =  10.361632917973209\n",
            "cost for i:  10  =  10.361632917973209\n",
            "cost for i:  11  =  10.361632917973209\n",
            "cost for i:  12  =  10.361632917973209\n",
            "cost for i:  13  =  10.361632917973209\n",
            "cost for i:  14  =  10.361632917973209\n",
            "cost for i:  15  =  10.361632917973209\n",
            "cost for i:  16  =  10.361632917973209\n",
            "cost for i:  17  =  10.361632917973209\n",
            "cost for i:  18  =  10.361632917973209\n",
            "cost for i:  19  =  10.361632917973209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10712\\3361659293.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a = np.array([theta, np.array(c)])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "theta = np.random.random(size = (X.shape[0]+1,1))\n",
        "epochs = 20\n",
        "theta_training = Logistic_Regression(X, y.flatten(), epochs, 0.5, theta, 0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4e39be",
      "metadata": {
        "id": "7b4e39be"
      },
      "outputs": [],
      "source": [
        "\n",
        "# theta_training = theta_training[:, -1]\n",
        "\n",
        "cost = theta_training[1]\n",
        "theta_training = theta_training[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fb0ae96",
      "metadata": {
        "id": "5fb0ae96",
        "outputId": "6c531215-da22-4ed8-9a9e-68f25e01cd51"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "numEpochs = np.arange(epochs)\n",
        "plt.plot(numEpochs, cost)\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Cost at each\")\n",
        "plt.title(\"Cost vs num of epochs\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbf058f",
      "metadata": {
        "id": "ffbf058f"
      },
      "outputs": [],
      "source": [
        "def confusion (true, predicted):\n",
        "  classNum = np.unique(true) \n",
        "  s = len(classNum) #s should be equal to 10. \n",
        "  confusion = np.zeros(shape=(s,s))  #since it is multiclass, we will have s * s matrix. \n",
        "  for i in range(s):\n",
        "    for j in range(s): \n",
        "      confusion[i][j] = np.sum( (predicted == classNum[j])  & (true == classNum[i]))\n",
        "  return confusion \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1396e41a",
      "metadata": {
        "id": "1396e41a"
      },
      "outputs": [],
      "source": [
        "def accuracy(true, predicted): \n",
        "    ...\n",
        "    conf = confusion (true, predicted)\n",
        "    accuracy = []\n",
        "    \n",
        "    classNum = len(np.unique(true))\n",
        "    for i in range(classNum):\n",
        "        TP = conf[i][i]  #true positive.\n",
        "        total = conf.sum() \n",
        "        TN = 0\n",
        "        #for true negative\n",
        "        for j in range(classNum):\n",
        "            for k in range(classNum):\n",
        "                if j != i and k != i:\n",
        "                    if (j < j - 1):\n",
        "                        j = j + 1\n",
        "                    if (k < k - 1):\n",
        "                        k = k + 1  \n",
        "                TN = TN + conf[j][k]\n",
        "    \n",
        "    accuracy.append((TP + TN)/total)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93a01c5",
      "metadata": {
        "id": "c93a01c5"
      },
      "outputs": [],
      "source": [
        "#evaluation function. \n",
        "def evaluation(theta, test_X, test_Y): \n",
        "    ...\n",
        "    m = test_X.shape[0]\n",
        "    predicted_labels = []\n",
        "    x_0 = np.ones((test_X.shape[1], 1))  \n",
        "    test_X = np.append(test_X, x_0.transpose(), axis =0)\n",
        "    predicted_labels = predict(test_X, theta_training, 0.5)\n",
        "\n",
        "    confusion_matrix = confusion(test_Y, predicted_labels)\n",
        "    a = accuracy(test_Y, predicted_labels)\n",
        "    eval = [confusion_matrix, a]\n",
        "    return eval\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad09da04",
      "metadata": {
        "id": "ad09da04",
        "outputId": "5b0b9f7a-326b-4121-eb28-2166de9f789e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "theta.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a90bcf2",
      "metadata": {
        "id": "5a90bcf2"
      },
      "outputs": [],
      "source": [
        "evaluating_theta = evaluation(theta_training.transpose(), X_test, yTest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae1eeb8",
      "metadata": {
        "id": "0ae1eeb8",
        "outputId": "6a8dc67b-76de-4f19-cdfe-4db977151548"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[12500.,     0.],\n",
              "        [12500.,     0.]]),\n",
              " None]"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluating_theta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1f0697",
      "metadata": {
        "id": "dc1f0697"
      },
      "source": [
        "### Part B: Use Scikit-learn\n",
        "\n",
        "In this part, use scikit-learn’s [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) implementation to train and test the logistic regression on the provided dataset. Use scikit-learn’s accuracy_score function to calculate the [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) and [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function to calculate confusion matrix on test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7893b68",
      "metadata": {
        "id": "c7893b68"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f00d2e9",
      "metadata": {
        "id": "1f00d2e9"
      },
      "outputs": [],
      "source": [
        "#Train: \n",
        "\n",
        "x_1 = np.array(x_1)\n",
        "x_2 = np.array(x_2)\n",
        "x_2 = np.reshape(x_2, (x_2.shape[0],1))\n",
        "X = x_1\n",
        "X = np.reshape(X,(x_1.shape[0],1))\n",
        "X = np.append(X, x_2, axis=1)\n",
        "X = X.transpose()\n",
        "y = np.array(y)\n",
        "# y = np.reshape(y, (y.shape[0],1))\n",
        "\n",
        "#Test:\n",
        "t_1 = np.array(t_1)\n",
        "t_2 = np.array(t_2)\n",
        "t_2 = np.reshape(t_2, (t_2.shape[0],1))\n",
        "X_test = t_1\n",
        "X_test = np.reshape(X_test,(t_1.shape[0],1))\n",
        "X_test = np.append(X_test, t_2, axis=1)\n",
        "X_test = X_test.transpose()\n",
        "yTest = np.array(t_y)\n",
        "# yTest = np.reshape(yTest, (yTest.shape[0],1))\n",
        "# print(y.flatten().shape)\n",
        "# print(X.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c26aa0c1",
      "metadata": {
        "id": "c26aa0c1",
        "outputId": "b873cceb-4a1a-4493-c00f-883f6f77d3ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [2, 25000]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32me:\\Fall 2022\\Machine Learning\\Assignments\\Programming Assignments\\Assignment 2\\UmamaNasirAbbasi_23100265_Assignment2.ipynb Cell 52\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Fall%202022/Machine%20Learning/Assignments/Programming%20Assignments/Assignment%202/UmamaNasirAbbasi_23100265_Assignment2.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m logistic_model \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Fall%202022/Machine%20Learning/Assignments/Programming%20Assignments/Assignment%202/UmamaNasirAbbasi_23100265_Assignment2.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m logistic_model\u001b[39m.\u001b[39;49mfit(temp_X, temp_y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Fall%202022/Machine%20Learning/Assignments/Programming%20Assignments/Assignment%202/UmamaNasirAbbasi_23100265_Assignment2.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m predict_y \u001b[39m=\u001b[39m logistic_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Fall%202022/Machine%20Learning/Assignments/Programming%20Assignments/Assignment%202/UmamaNasirAbbasi_23100265_Assignment2.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m accuracy \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(yTest,predict_y)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1138\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1138\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1139\u001b[0m     X,\n\u001b[0;32m   1140\u001b[0m     y,\n\u001b[0;32m   1141\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1142\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1143\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1144\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1145\u001b[0m )\n\u001b[0;32m   1146\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1092\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1092\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 25000]"
          ]
        }
      ],
      "source": [
        "\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(temp_X, temp_y)\n",
        "\n",
        "predict_y = logistic_model.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(yTest,predict_y)\n",
        "logistic_confusion_matrix = metrics.confusion_matrix(yTest, predict_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd569b58",
      "metadata": {
        "id": "dd569b58"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(logistic_confusion_matrix, annot = True, fmt = \".3f\", linewidth = 0.6, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel(\"Gold Labels\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.title(\"Accuracy Score : \", str(accuracy))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "970a2a4939579a4c22872227820a264ec023ee5692739211cbaca24386397975"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}